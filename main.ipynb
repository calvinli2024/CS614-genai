{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calvinli2024/CS614-genai/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d69d2840",
      "metadata": {
        "id": "d69d2840"
      },
      "source": [
        "# Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc729135",
      "metadata": {
        "id": "fc729135"
      },
      "outputs": [],
      "source": [
        "%pip install evaluate peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5063f33",
      "metadata": {
        "id": "a5063f33"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Any\n",
        "\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    AutoModelForCausalLM\n",
        ")\n",
        "\n",
        "import evaluate\n",
        "\n",
        "import itertools\n",
        "import json\n",
        "from copy import deepcopy\n",
        "\n",
        "from peft import LoraConfig, TaskType, get_peft_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c8a8a5f",
      "metadata": {
        "id": "5c8a8a5f"
      },
      "source": [
        "# Configuration & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "219bb5b4",
      "metadata": {
        "id": "219bb5b4"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"Qwen/Qwen3-0.6B\"  # 4B, open-weight, causal LM for research use.[web:10]\n",
        "DATASET_NAME = \"sh0416/ag_news\"  # AG News topic classification dataset.[web:8]\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21c40442",
      "metadata": {
        "id": "21c40442"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f17fa8ac",
      "metadata": {
        "id": "f17fa8ac"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(DATASET_NAME)  # splits: train, test.[web:8]\n",
        "\n",
        "dataset_small = {}\n",
        "for split in dataset.keys():\n",
        "    dataset_small[split] = dataset[split].shuffle(seed=42).select(range(7000))\n",
        "\n",
        "dataset = dataset_small\n",
        "\n",
        "label_names = dataset[\"train\"][\"label\"]\n",
        "num_labels = len(label_names)\n",
        "\n",
        "# For a small, quick run, you can optionally subsample.\n",
        "# dataset[\"train\"] = dataset[\"train\"].shuffle(seed=42).select(range(2000))\n",
        "# dataset[\"test\"] = dataset[\"test\"].shuffle(seed=42).select(range(500))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd832b22",
      "metadata": {
        "id": "dd832b22"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f135bcd2",
      "metadata": {
        "id": "f135bcd2"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Ensure we have a padding token (Qwen is a causal LM)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac5d9175",
      "metadata": {
        "id": "ac5d9175"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "085db5df",
      "metadata": {
        "id": "085db5df"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=num_labels,\n",
        "    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ")\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    inference_mode=False, # set to False for training\n",
        "    r=8, # dimension of the smaller matrices\n",
        "    lora_alpha=32, # scaling factor\n",
        "    lora_dropout=0.1 # dropout of LoRA layers\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10387705",
      "metadata": {
        "id": "10387705"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2221af",
      "metadata": {
        "id": "fe2221af"
      },
      "outputs": [],
      "source": [
        "max_length = 256\n",
        "\n",
        "def preprocess(dataset_split):\n",
        "    def run_tokenizer(row):\n",
        "      return tokenizer(\n",
        "          row[\"text\"],\n",
        "          padding=\"max_length\",\n",
        "          truncation=True,\n",
        "          max_length=max_length,\n",
        "      )\n",
        "\n",
        "    def add_text(row):\n",
        "      row[\"text\"] = row[\"title\"] + \" \" + row[\"description\"]\n",
        "\n",
        "      return row\n",
        "\n",
        "    dataset_split = dataset_split.map(add_text)\n",
        "\n",
        "    encoded_dataset = dataset_split.map(run_tokenizer, batched=True)\n",
        "    encoded_dataset = encoded_dataset.remove_columns(\n",
        "        [col for col in encoded_dataset.column_names if col not in [\"input_ids\", \"attention_mask\", \"label\"]]\n",
        "    )\n",
        "\n",
        "    return encoded_dataset.with_format(\"torch\")\n",
        "\n",
        "train_dataset = preprocess(dataset['train'])\n",
        "eval_dataset = preprocess(dataset['test'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61ae7f96",
      "metadata": {
        "id": "61ae7f96"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6925906a",
      "metadata": {
        "id": "6925906a"
      },
      "outputs": [],
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=-1)\n",
        "    results = accuracy.compute(predictions=preds, references=labels)\n",
        "    results.update(\n",
        "        f1.compute(predictions=preds, references=labels, average=\"macro\")\n",
        "    )\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8b54633",
      "metadata": {
        "id": "d8b54633"
      },
      "source": [
        "# Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99a6b1ec",
      "metadata": {
        "id": "99a6b1ec"
      },
      "source": [
        "## Training Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "527fc936",
      "metadata": {
        "id": "527fc936"
      },
      "outputs": [],
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\"./qwen3_agnews_grid\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    warmup_steps=0, # Setting to 0 to replace warmup_ratio, as it is deprecated.\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    gradient_accumulation_steps=4,\n",
        "    fp16=False, # Changed from torch.cuda.is_available() to False to resolve bfloat16 AMP issue\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer_kwargs = dict(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "329362be",
      "metadata": {
        "id": "329362be"
      },
      "source": [
        "## Search Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08fd5ee0",
      "metadata": {
        "id": "08fd5ee0"
      },
      "outputs": [],
      "source": [
        "search_space = {\n",
        "    \"learning_rate\": [1e-3, 1e-2],\n",
        "    \"num_train_epochs\": [1, 2, 3],\n",
        "    \"per_device_train_batch_size\": [8],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "208870ac",
      "metadata": {
        "id": "208870ac"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "062e0479",
      "metadata": {
        "id": "062e0479"
      },
      "outputs": [],
      "source": [
        "def run_single_experiment(\n",
        "    base_training_args: TrainingArguments,\n",
        "    trainer_cls,\n",
        "    trainer_kwargs: Dict[str, Any],\n",
        "    hp_config: Dict[str, Any],\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    base_training_args: a TrainingArguments object with default values.\n",
        "    trainer_cls: usually `Trainer`.\n",
        "    trainer_kwargs: dict with keys like model, train_dataset, eval_dataset, tokenizer, compute_metrics.\n",
        "    hp_config: specific hyperparameters for this run (e.g. lr, epochs, batch size).\n",
        "    \"\"\"\n",
        "    # 1) Clone TrainingArguments and override selected fields\n",
        "    args_dict = base_training_args.to_dict()\n",
        "    for k, v in hp_config.items():\n",
        "        args_dict[k] = v\n",
        "\n",
        "    training_args = TrainingArguments(**args_dict)\n",
        "\n",
        "    # 2) Create a fresh Trainer (important if model should be reinitialized externally)\n",
        "    trainer = trainer_cls(\n",
        "        args=training_args,\n",
        "        **trainer_kwargs,\n",
        "    )\n",
        "\n",
        "    # 3) Train and evaluate\n",
        "    train_output = trainer.train()\n",
        "    eval_metrics = trainer.evaluate()\n",
        "\n",
        "    result = {\n",
        "        \"hp_config\": hp_config,\n",
        "        \"train_runtime\": train_output.training_time,\n",
        "        \"train_samples\": train_output.metrics.get(\"train_samples\", None),\n",
        "        \"eval_metrics\": eval_metrics,\n",
        "    }\n",
        "\n",
        "    return result\n",
        "\n",
        "def grid_search_hyperparams(\n",
        "    base_training_args: TrainingArguments,\n",
        "    trainer_cls,\n",
        "    trainer_kwargs: Dict[str, Any],\n",
        "    search_space: Dict[str, List[Any]],\n",
        "    results_path: str = \"grid_search_results.jsonl\",\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    search_space: dict of hyperparameter -> list of values, e.g.\n",
        "        {\n",
        "            \"learning_rate\": [5e-5, 1e-4],\n",
        "            \"num_train_epochs\": [1, 2, 3],\n",
        "            \"per_device_train_batch_size\": [4, 8],\n",
        "        }\n",
        "    \"\"\"\n",
        "    # Cartesian product of search space.[web:14][web:17]\n",
        "    keys = list(search_space.keys())\n",
        "    value_lists = [search_space[k] for k in keys]\n",
        "\n",
        "    all_results: List[Dict[str, Any]] = []\n",
        "\n",
        "    os.makedirs(os.path.dirname(results_path) or \".\", exist_ok=True)\n",
        "\n",
        "    with open(results_path, \"w\", encoding=\"utf-8\") as f_out:\n",
        "        for combo in itertools.product(*value_lists):\n",
        "            hp_config = {k: v for k, v in zip(keys, combo)}\n",
        "            print(\"\\n=== Running config:\", hp_config, \"===\")\n",
        "\n",
        "            result = run_single_experiment(\n",
        "                base_training_args=base_training_args,\n",
        "                trainer_cls=trainer_cls,\n",
        "                trainer_kwargs=deepcopy(trainer_kwargs),\n",
        "                hp_config=hp_config,\n",
        "            )\n",
        "\n",
        "            # Persist each result as one JSON line\n",
        "            f_out.write(json.dumps(result) + \"\\n\")\n",
        "            f_out.flush()\n",
        "\n",
        "            all_results.append(result)\n",
        "\n",
        "    return all_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd6829fa",
      "metadata": {
        "id": "bd6829fa"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa47f6ab",
      "metadata": {
        "id": "fa47f6ab"
      },
      "outputs": [],
      "source": [
        "results = grid_search_hyperparams(\n",
        "    base_training_args=training_arguments,\n",
        "    trainer_cls=Trainer,\n",
        "    trainer_kwargs=trainer_kwargs,\n",
        "    search_space=search_space,\n",
        "    results_path=\"grid_search_results.jsonl\",\n",
        ")\n",
        "\n",
        "# 5) Pick best config by metric (e.g. accuracy)\n",
        "best = max(results, key=lambda r: r[\"eval_metrics\"].get(\"eval_accuracy\", 0.0))\n",
        "print(\"Best config:\", best[\"hp_config\"])\n",
        "print(\"Best metrics:\", best[\"eval_metrics\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "466e425e",
      "metadata": {
        "id": "466e425e"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55ed7342",
      "metadata": {
        "id": "55ed7342"
      },
      "outputs": [],
      "source": [
        "id2label = {i: name for i, name in enumerate(label_names)}\n",
        "\n",
        "def infer(texts: List[str]):\n",
        "    encodings = tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encodings)\n",
        "        logits = outputs.logits\n",
        "        preds = logits.argmax(dim=-1).cpu().tolist()\n",
        "\n",
        "    return [id2label[p] for p in preds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b109520b",
      "metadata": {
        "id": "b109520b"
      },
      "outputs": [],
      "source": [
        "example_texts = [\n",
        "    \"Stocks rose today as the market reacted positively to the latest earnings reports.\",\n",
        "    \"The team secured a last-minute victory in the championship game.\",\n",
        "]\n",
        "\n",
        "print(infer(example_texts))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}