{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31260,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calvinli2024/CS614-genai/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Packages"
      ],
      "metadata": {
        "id": "d69d2840"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install evaluate peft"
      ],
      "metadata": {
        "id": "fc729135",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T08:46:45.504628Z",
          "iopub.execute_input": "2026-02-17T08:46:45.505456Z",
          "iopub.status.idle": "2026-02-17T08:46:51.929111Z",
          "shell.execute_reply.started": "2026-02-17T08:46:45.505411Z",
          "shell.execute_reply": "2026-02-17T08:46:51.928189Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Any\n",
        "\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    AutoModelForCausalLM,\n",
        "    pipeline\n",
        ")\n",
        "\n",
        "import evaluate\n",
        "from evaluate import evaluator\n",
        "\n",
        "import itertools\n",
        "import json\n",
        "from copy import deepcopy\n",
        "\n",
        "from peft import LoraConfig, TaskType, get_peft_model"
      ],
      "metadata": {
        "id": "a5063f33",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T08:46:51.930882Z",
          "iopub.execute_input": "2026-02-17T08:46:51.931189Z",
          "iopub.status.idle": "2026-02-17T08:47:36.932817Z",
          "shell.execute_reply.started": "2026-02-17T08:46:51.931158Z",
          "shell.execute_reply": "2026-02-17T08:47:36.931819Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "metadata": {
        "id": "219bb5b4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T08:47:36.933821Z",
          "iopub.execute_input": "2026-02-17T08:47:36.934543Z",
          "iopub.status.idle": "2026-02-17T08:47:36.939045Z",
          "shell.execute_reply.started": "2026-02-17T08:47:36.934481Z",
          "shell.execute_reply": "2026-02-17T08:47:36.937905Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "21c40442"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"sh0416/ag_news\")\n",
        "\n",
        "dataset = {\n",
        "    \"train\": dataset[\"train\"].shuffle(seed=42).select(range(5000)),\n",
        "    \"valid\": dataset[\"train\"].shuffle(seed=42).select(range(5000, 6000)),\n",
        "    \"test\": dataset[\"test\"].shuffle(seed=42).select(range(2000))\n",
        "}\n",
        "\n",
        "num_labels = len(set(dataset[\"train\"][\"label\"]))"
      ],
      "metadata": {
        "id": "f17fa8ac",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T08:47:36.940090Z",
          "iopub.execute_input": "2026-02-17T08:47:36.940396Z",
          "iopub.status.idle": "2026-02-17T08:47:42.086774Z",
          "shell.execute_reply.started": "2026-02-17T08:47:36.940368Z",
          "shell.execute_reply": "2026-02-17T08:47:42.085921Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer"
      ],
      "metadata": {
        "id": "dd832b22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\")\n",
        "\n",
        "# Ensure we have a padding token (Qwen is a causal LM)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "f135bcd2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T08:47:42.088913Z",
          "iopub.execute_input": "2026-02-17T08:47:42.089228Z",
          "iopub.status.idle": "2026-02-17T08:47:44.035527Z",
          "shell.execute_reply.started": "2026-02-17T08:47:42.089199Z",
          "shell.execute_reply": "2026-02-17T08:47:44.034702Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "xrhA-fo_kx63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"Qwen/Qwen3-0.6B\",\n",
        "    num_labels=num_labels,\n",
        "    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ")\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    inference_mode=False, # set to False for training\n",
        "    r=8, # dimension of the smaller matrices\n",
        "    lora_alpha=32, # scaling factor\n",
        "    lora_dropout=0.1 # dropout of LoRA layers\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "085db5df",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T08:47:44.036624Z",
          "iopub.execute_input": "2026-02-17T08:47:44.036957Z",
          "iopub.status.idle": "2026-02-17T08:47:49.934588Z",
          "shell.execute_reply.started": "2026-02-17T08:47:44.036921Z",
          "shell.execute_reply": "2026-02-17T08:47:49.933707Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess"
      ],
      "metadata": {
        "id": "10387705"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 256\n",
        "\n",
        "def preprocess(dataset_split, select_columns: List[str]):\n",
        "    def run_tokenizer(row):\n",
        "      return tokenizer(\n",
        "          row[\"text\"],\n",
        "          padding=\"max_length\",\n",
        "          truncation=True,\n",
        "          max_length=max_length,\n",
        "      )\n",
        "\n",
        "    def prepare_columns(row):\n",
        "      row[\"text\"] = row[\"title\"] + \" \" + row[\"description\"]\n",
        "      row[\"label\"] = row[\"label\"] - 1\n",
        "\n",
        "      return row\n",
        "\n",
        "    dataset_split = dataset_split.map(prepare_columns)\n",
        "\n",
        "    encoded_dataset = dataset_split.map(run_tokenizer, batched=True)\n",
        "\n",
        "    encoded_dataset = encoded_dataset.remove_columns(\n",
        "        [col for col in encoded_dataset.column_names if col not in select_columns]\n",
        "    )\n",
        "\n",
        "    return encoded_dataset.with_format(\"torch\")\n",
        "\n",
        "train_dataset = preprocess(dataset['train'], [\"input_ids\", \"attention_mask\", \"label\"])\n",
        "valid_dataset = preprocess(dataset['valid'], [\"input_ids\", \"attention_mask\", \"label\"])\n",
        "test_dataset = preprocess(dataset['test'], [\"label\", \"text\"])"
      ],
      "metadata": {
        "id": "fe2221af",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T08:47:49.935773Z",
          "iopub.execute_input": "2026-02-17T08:47:49.936067Z",
          "iopub.status.idle": "2026-02-17T08:47:54.622642Z",
          "shell.execute_reply.started": "2026-02-17T08:47:49.936027Z",
          "shell.execute_reply": "2026-02-17T08:47:54.621775Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics"
      ],
      "metadata": {
        "id": "61ae7f96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=-1)\n",
        "    results = accuracy.compute(predictions=preds, references=labels)\n",
        "    results.update(\n",
        "        f1.compute(predictions=preds, references=labels, average=\"macro\")\n",
        "    )\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "6925906a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T08:47:54.623873Z",
          "iopub.execute_input": "2026-02-17T08:47:54.624168Z",
          "iopub.status.idle": "2026-02-17T08:47:56.502436Z",
          "shell.execute_reply.started": "2026-02-17T08:47:54.624140Z",
          "shell.execute_reply": "2026-02-17T08:47:56.501583Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "d8b54633"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Arguments"
      ],
      "metadata": {
        "id": "99a6b1ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\"./qwen3_agnews_grid\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    warmup_steps=0,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    gradient_accumulation_steps=4,\n",
        "    fp16=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer_kwargs = dict(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "527fc936",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T08:47:56.503951Z",
          "iopub.execute_input": "2026-02-17T08:47:56.504829Z",
          "iopub.status.idle": "2026-02-17T08:47:56.527410Z",
          "shell.execute_reply.started": "2026-02-17T08:47:56.504774Z",
          "shell.execute_reply": "2026-02-17T08:47:56.526430Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search Space"
      ],
      "metadata": {
        "id": "329362be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = {}\n",
        "\n",
        "idx = 0\n",
        "for learning_rate in [1e-4, 1e-3]:\n",
        "    for num_train_epochs in [1, 2, 3]:\n",
        "        hyperparameters[idx] = {\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"num_train_epochs\": num_train_epochs\n",
        "        }\n",
        "\n",
        "        idx += 1\n"
      ],
      "metadata": {
        "id": "08fd5ee0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T08:47:56.528876Z",
          "iopub.execute_input": "2026-02-17T08:47:56.529149Z",
          "iopub.status.idle": "2026-02-17T08:47:57.056950Z",
          "shell.execute_reply.started": "2026-02-17T08:47:56.529124Z",
          "shell.execute_reply": "2026-02-17T08:47:57.055951Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "208870ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_single_experiment(\n",
        "    base_training_args: TrainingArguments,\n",
        "    trainer_cls,\n",
        "    trainer_kwargs: Dict[str, Any],\n",
        "    hp_config: Dict[str, float|int],\n",
        "    idx: int\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    base_training_args: a TrainingArguments object with default values.\n",
        "    trainer_cls: usually `Trainer`.\n",
        "    trainer_kwargs: dict with keys like model, train_dataset, eval_dataset, tokenizer, compute_metrics.\n",
        "    hp_config: specific hyperparameters for this run (e.g. lr, epochs, batch size).\n",
        "    \"\"\"\n",
        "    # 1) Clone TrainingArguments and override selected fields\n",
        "    args_dict = base_training_args.to_dict()\n",
        "    for k, v in hp_config.items():\n",
        "        args_dict[k] = v\n",
        "\n",
        "    training_args = TrainingArguments(**args_dict)\n",
        "\n",
        "    # 2) Create a fresh Trainer (important if model should be reinitialized externally)\n",
        "    trainer = trainer_cls(\n",
        "        args=training_args,\n",
        "        **trainer_kwargs,\n",
        "    )\n",
        "\n",
        "    # 3) Train and evaluate\n",
        "    train_output = trainer.train()\n",
        "    eval_metrics = trainer.evaluate()\n",
        "\n",
        "    trainer.save_model(f\"checkpoint_{idx}\")\n",
        "\n",
        "    result = {\n",
        "        \"hp_config\": hp_config,\n",
        "        \"train_samples\": train_output.metrics.get(\"train_samples\", None),\n",
        "        \"eval_metrics\": eval_metrics,\n",
        "    }\n",
        "\n",
        "    return result\n",
        "\n",
        "def grid_search_hyperparams(\n",
        "    base_training_args: TrainingArguments,\n",
        "    trainer_cls,\n",
        "    trainer_kwargs: Dict[str, Any],\n",
        "    hyperparameters: Dict[int, Dict[str, int|float]],\n",
        "    results_path: str = \"grid_search_results.jsonl\",\n",
        ") -> List[Dict[str, Any]]:\n",
        "    all_results = {}\n",
        "\n",
        "    os.makedirs(os.path.dirname(results_path) or \".\", exist_ok=True)\n",
        "\n",
        "    with open(results_path, \"w\", encoding=\"utf-8\") as f_out:\n",
        "        for idx, combo in hyperparameters.items():\n",
        "            print(\"\\n=== Running config:\", combo, \"===\")\n",
        "\n",
        "            result = run_single_experiment(\n",
        "                base_training_args=base_training_args,\n",
        "                trainer_cls=trainer_cls,\n",
        "                trainer_kwargs=deepcopy(trainer_kwargs),\n",
        "                hp_config=combo,\n",
        "                idx=idx\n",
        "            )\n",
        "\n",
        "            # Persist each result as one JSON line\n",
        "            f_out.write(json.dumps(result) + \"\\n\")\n",
        "            f_out.flush()\n",
        "\n",
        "            all_results[idx] = result\n",
        "\n",
        "    return all_results"
      ],
      "metadata": {
        "id": "062e0479",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T08:47:57.058201Z",
          "iopub.execute_input": "2026-02-17T08:47:57.058549Z",
          "iopub.status.idle": "2026-02-17T08:47:57.081176Z",
          "shell.execute_reply.started": "2026-02-17T08:47:57.058488Z",
          "shell.execute_reply": "2026-02-17T08:47:57.080302Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "bd6829fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = grid_search_hyperparams(\n",
        "    base_training_args=training_arguments,\n",
        "    trainer_cls=Trainer,\n",
        "    trainer_kwargs=trainer_kwargs,\n",
        "    hyperparameters=hyperparameters,\n",
        "    results_path=\"grid_search_results.jsonl\",\n",
        ")"
      ],
      "metadata": {
        "id": "fa47f6ab",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T08:47:57.082282Z",
          "iopub.execute_input": "2026-02-17T08:47:57.082657Z",
          "iopub.status.idle": "2026-02-17T08:49:24.976265Z",
          "shell.execute_reply.started": "2026-02-17T08:47:57.082626Z",
          "shell.execute_reply": "2026-02-17T08:49:24.974267Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "best_config = max(results.items(), key=lambda r: r[1][\"eval_metrics\"].get(\"eval_f1\", 0.0))\n",
        "\n",
        "print(\"Best index:\", best_config[0])\n",
        "print(\"Best config:\", best_config[1][\"hp_config\"])\n",
        "print(\"Best metrics:\", best_config[1][\"eval_metrics\"])"
      ],
      "metadata": {
        "trusted": true,
        "id": "6fpkVLBxwETe",
        "execution": {
          "iopub.status.busy": "2026-02-17T08:49:24.977530Z",
          "iopub.status.idle": "2026-02-17T08:49:24.978037Z",
          "shell.execute_reply.started": "2026-02-17T08:49:24.977800Z",
          "shell.execute_reply": "2026-02-17T08:49:24.977830Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "466e425e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    f\"./checkpoint_{best_config[0]}\",\n",
        "    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ")\n",
        "\n",
        "results = evaluator(\"text-classification\").compute(\n",
        "    model_or_pipeline=pipeline(\"text-classification\", model=model),\n",
        "    data=test_dataset,\n",
        "    metric=evaluate.load(\"f1\"),\n",
        "    input_column=\"text\",\n",
        "    label_column=\"label\",\n",
        "    strategy=\"bootstrap\",\n",
        "    n_resamples=200\n",
        ")\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "11e427eb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T08:49:24.979810Z",
          "iopub.status.idle": "2026-02-17T08:49:24.980273Z",
          "shell.execute_reply.started": "2026-02-17T08:49:24.980053Z",
          "shell.execute_reply": "2026-02-17T08:49:24.980081Z"
        }
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}