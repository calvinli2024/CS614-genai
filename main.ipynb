{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69d2840",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc729135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (1.3.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (26.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (0.21.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2026.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.7.0->evaluate) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.7.0->evaluate) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.7.0->evaluate) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.7.0->evaluate) (8.3.1)\n"
     ]
    }
   ],
   "source": [
    "%pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5063f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Any\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import itertools\n",
    "import json\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8a8a5f",
   "metadata": {},
   "source": [
    "# Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "219bb5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen3-4B\"  # 4B, open-weight, causal LM for research use.[web:10]\n",
    "DATASET_NAME = \"sh0416/ag_news\"  # AG News topic classification dataset.[web:8]\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c40442",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f17fa8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38253a3b71c4a7c82e2787a060997a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0383cfc9b54c4f0e817aa4ad94737a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.jsonl:   0%|          | 0.00/33.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a640e355f2b4d42992293325b221dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fb23e34d1e4ec18f8d007c4adbe42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4fabbac23b4d1c8564e4b48a35a8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Value' object has no attribute 'names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2460378051.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_NAME\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# splits: train, test.[web:8]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlabel_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Value' object has no attribute 'names'"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(DATASET_NAME)  # splits: train, test.[web:8]\n",
    "\n",
    "label_names = dataset[\"train\"].features[\"label\"].names\n",
    "num_labels = len(label_names)\n",
    "\n",
    "# For a small, quick run, you can optionally subsample.\n",
    "# dataset[\"train\"] = dataset[\"train\"].shuffle(seed=42).select(range(2000))\n",
    "# dataset[\"test\"] = dataset[\"test\"].shuffle(seed=42).select(range(500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd832b22",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Ensure we have a padding token (Qwen is a causal LM)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d9175",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085db5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels,\n",
    "    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10387705",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2221af",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256\n",
    "\n",
    "def preprocess(examples):\n",
    "    # AG News has \"text\" and \"label\".[web:8]\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess, batched=True)\n",
    "encoded_dataset = encoded_dataset.remove_columns(\n",
    "    [col for col in encoded_dataset[\"train\"].column_names if col not in [\"input_ids\", \"attention_mask\", \"label\"]]\n",
    ")\n",
    "encoded_dataset = encoded_dataset.with_format(\"torch\")\n",
    "\n",
    "train_dataset = encoded_dataset[\"train\"]\n",
    "eval_dataset = encoded_dataset[\"test\"]  # or create your own split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ae7f96",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6925906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    results = accuracy.compute(predictions=preds, references=labels)\n",
    "    results.update(\n",
    "        f1.compute(predictions=preds, references=labels, average=\"macro\")\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b54633",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6b1ec",
   "metadata": {},
   "source": [
    "## Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527fc936",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"./qwen3_agnews_grid\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    gradient_accumulation_steps=4,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer_kwargs = dict(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329362be",
   "metadata": {},
   "source": [
    "## Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fd5ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"learning_rate\": [5e-5, 1e-4],\n",
    "    \"num_train_epochs\": [1, 2, 3],\n",
    "    \"per_device_train_batch_size\": [4, 8],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208870ac",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062e0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_experiment(\n",
    "    base_training_args: TrainingArguments,\n",
    "    trainer_cls,\n",
    "    trainer_kwargs: Dict[str, Any],\n",
    "    hp_config: Dict[str, Any],\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    base_training_args: a TrainingArguments object with default values.\n",
    "    trainer_cls: usually `Trainer`.\n",
    "    trainer_kwargs: dict with keys like model, train_dataset, eval_dataset, tokenizer, compute_metrics.\n",
    "    hp_config: specific hyperparameters for this run (e.g. lr, epochs, batch size).\n",
    "    \"\"\"\n",
    "    # 1) Clone TrainingArguments and override selected fields\n",
    "    args_dict = base_training_args.to_dict()\n",
    "    for k, v in hp_config.items():\n",
    "        args_dict[k] = v\n",
    "\n",
    "    training_args = TrainingArguments(**args_dict)\n",
    "\n",
    "    # 2) Create a fresh Trainer (important if model should be reinitialized externally)\n",
    "    trainer = trainer_cls(\n",
    "        args=training_args,\n",
    "        **trainer_kwargs,\n",
    "    )\n",
    "\n",
    "    # 3) Train and evaluate\n",
    "    train_output = trainer.train()\n",
    "    eval_metrics = trainer.evaluate()\n",
    "\n",
    "    result = {\n",
    "        \"hp_config\": hp_config,\n",
    "        \"train_runtime\": train_output.training_time,\n",
    "        \"train_samples\": train_output.metrics.get(\"train_samples\", None),\n",
    "        \"eval_metrics\": eval_metrics,\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "def grid_search_hyperparams(\n",
    "    base_training_args: TrainingArguments,\n",
    "    trainer_cls,\n",
    "    trainer_kwargs: Dict[str, Any],\n",
    "    search_space: Dict[str, List[Any]],\n",
    "    results_path: str = \"grid_search_results.jsonl\",\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    search_space: dict of hyperparameter -> list of values, e.g.\n",
    "        {\n",
    "            \"learning_rate\": [5e-5, 1e-4],\n",
    "            \"num_train_epochs\": [1, 2, 3],\n",
    "            \"per_device_train_batch_size\": [4, 8],\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Cartesian product of search space.[web:14][web:17]\n",
    "    keys = list(search_space.keys())\n",
    "    value_lists = [search_space[k] for k in keys]\n",
    "\n",
    "    all_results: List[Dict[str, Any]] = []\n",
    "\n",
    "    os.makedirs(os.path.dirname(results_path) or \".\", exist_ok=True)\n",
    "\n",
    "    with open(results_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        for combo in itertools.product(*value_lists):\n",
    "            hp_config = {k: v for k, v in zip(keys, combo)}\n",
    "            print(\"\\n=== Running config:\", hp_config, \"===\")\n",
    "\n",
    "            result = run_single_experiment(\n",
    "                base_training_args=base_training_args,\n",
    "                trainer_cls=trainer_cls,\n",
    "                trainer_kwargs=deepcopy(trainer_kwargs),\n",
    "                hp_config=hp_config,\n",
    "            )\n",
    "\n",
    "            # Persist each result as one JSON line\n",
    "            f_out.write(json.dumps(result) + \"\\n\")\n",
    "            f_out.flush()\n",
    "\n",
    "            all_results.append(result)\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6829fa",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa47f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grid_search_hyperparams(\n",
    "    base_training_args=training_arguments,\n",
    "    trainer_cls=Trainer,\n",
    "    trainer_kwargs=trainer_kwargs,\n",
    "    search_space=search_space,\n",
    "    results_path=\"grid_search_results.jsonl\",\n",
    ")\n",
    "\n",
    "# 5) Pick best config by metric (e.g. accuracy)\n",
    "best = max(results, key=lambda r: r[\"eval_metrics\"].get(\"eval_accuracy\", 0.0))\n",
    "print(\"Best config:\", best[\"hp_config\"])\n",
    "print(\"Best metrics:\", best[\"eval_metrics\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e425e",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ed7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: name for i, name in enumerate(label_names)}\n",
    "\n",
    "def infer(texts: List[str]):\n",
    "    encodings = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings)\n",
    "        logits = outputs.logits\n",
    "        preds = logits.argmax(dim=-1).cpu().tolist()\n",
    "        \n",
    "    return [id2label[p] for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b109520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_texts = [\n",
    "    \"Stocks rose today as the market reacted positively to the latest earnings reports.\",\n",
    "    \"The team secured a last-minute victory in the championship game.\",\n",
    "]\n",
    "\n",
    "print(infer(example_texts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
