{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31260,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calvinli2024/CS614-genai/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Packages"
      ],
      "metadata": {
        "id": "d69d2840"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install evaluate peft"
      ],
      "metadata": {
        "id": "fc729135",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T05:24:55.304734Z",
          "iopub.execute_input": "2026-02-17T05:24:55.305102Z",
          "iopub.status.idle": "2026-02-17T05:25:00.091975Z",
          "shell.execute_reply.started": "2026-02-17T05:24:55.305075Z",
          "shell.execute_reply": "2026-02-17T05:25:00.091145Z"
        },
        "outputId": "b8e10955-a9f7-4411-b8e5-e68710482e36"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.4.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\nRequirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.18)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (26.0rc2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft) (6.0.3)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.8.0+cu126)\nRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from peft) (4.57.1)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft) (1.11.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft) (0.6.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.3)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2026.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->peft) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->peft) (0.22.1)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.12.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.6\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Any\n",
        "\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    AutoModelForCausalLM,\n",
        "    pipeline\n",
        ")\n",
        "\n",
        "import evaluate\n",
        "from evaluate import evaluator\n",
        "\n",
        "import itertools\n",
        "import json\n",
        "from copy import deepcopy\n",
        "\n",
        "from peft import LoraConfig, TaskType, get_peft_model"
      ],
      "metadata": {
        "id": "a5063f33",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T05:25:00.093681Z",
          "iopub.execute_input": "2026-02-17T05:25:00.093941Z",
          "iopub.status.idle": "2026-02-17T05:25:32.795536Z",
          "shell.execute_reply.started": "2026-02-17T05:25:00.093913Z",
          "shell.execute_reply": "2026-02-17T05:25:32.794871Z"
        },
        "outputId": "ff2b626c-ad7c-4036-bb1e-188a032481e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2026-02-17 05:25:16.571776: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1771305916.781959      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1771305916.845002      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1771305917.365385      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771305917.365426      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771305917.365429      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771305917.365431      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "metadata": {
        "id": "219bb5b4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T05:25:32.796332Z",
          "iopub.execute_input": "2026-02-17T05:25:32.796957Z",
          "iopub.status.idle": "2026-02-17T05:25:32.800617Z",
          "shell.execute_reply.started": "2026-02-17T05:25:32.796928Z",
          "shell.execute_reply": "2026-02-17T05:25:32.799880Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "21c40442"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"sh0416/ag_news\")\n",
        "\n",
        "dataset = {\n",
        "    \"train\": dataset[\"train\"].shuffle(seed=42).select(range(5000)),\n",
        "    \"valid\": dataset[\"train\"].shuffle(seed=42).select(range(5000, 6000)),\n",
        "    \"test\": dataset[\"test\"].shuffle(seed=42).select(range(2000))\n",
        "}\n",
        "\n",
        "num_labels = len(set(dataset[\"train\"][\"label\"]))"
      ],
      "metadata": {
        "id": "f17fa8ac",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T05:25:32.802374Z",
          "iopub.execute_input": "2026-02-17T05:25:32.802590Z",
          "iopub.status.idle": "2026-02-17T05:25:35.289576Z",
          "shell.execute_reply.started": "2026-02-17T05:25:32.802568Z",
          "shell.execute_reply": "2026-02-17T05:25:35.288851Z"
        },
        "colab": {
          "referenced_widgets": [
            "74e2e00df3ab43569fb59843d49d2f3c",
            "b17e14659da3421493fcb0383fe764f8",
            "62c131b84cdb4032ba903366f54a18d1",
            "458688eedfa744de8f362ee590b981b4",
            "9a3f34c8817f474b81f57683a153398d"
          ]
        },
        "outputId": "e4462679-e972-424c-fcc6-73119c03f554"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74e2e00df3ab43569fb59843d49d2f3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train.jsonl:   0%|          | 0.00/33.7M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b17e14659da3421493fcb0383fe764f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "test.jsonl: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62c131b84cdb4032ba903366f54a18d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "458688eedfa744de8f362ee590b981b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a3f34c8817f474b81f57683a153398d"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer"
      ],
      "metadata": {
        "id": "dd832b22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\")\n",
        "\n",
        "# Ensure we have a padding token (Qwen is a causal LM)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "f135bcd2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T05:25:35.290537Z",
          "iopub.execute_input": "2026-02-17T05:25:35.290928Z",
          "iopub.status.idle": "2026-02-17T05:25:36.651138Z",
          "shell.execute_reply.started": "2026-02-17T05:25:35.290902Z",
          "shell.execute_reply": "2026-02-17T05:25:36.650348Z"
        },
        "colab": {
          "referenced_widgets": [
            "e0beb1476cd24aa69e4339aa3199b26f",
            "59020f092a664f85b62047400925599f",
            "94c7937d59fb490eb9fd8cd537520d08",
            "b0dab48a3d574666b38095d94e7910c9"
          ]
        },
        "outputId": "bd025390-6757-4793-c733-f9bb640e1e81"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0beb1476cd24aa69e4339aa3199b26f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59020f092a664f85b62047400925599f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94c7937d59fb490eb9fd8cd537520d08"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0dab48a3d574666b38095d94e7910c9"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "xrhA-fo_kx63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"Qwen/Qwen3-0.6B\",\n",
        "    num_labels=num_labels,\n",
        "    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ")\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    inference_mode=False, # set to False for training\n",
        "    r=8, # dimension of the smaller matrices\n",
        "    lora_alpha=32, # scaling factor\n",
        "    lora_dropout=0.1 # dropout of LoRA layers\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "085db5df",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T05:25:36.652163Z",
          "iopub.execute_input": "2026-02-17T05:25:36.652469Z",
          "iopub.status.idle": "2026-02-17T05:25:41.528645Z",
          "shell.execute_reply.started": "2026-02-17T05:25:36.652436Z",
          "shell.execute_reply": "2026-02-17T05:25:41.527873Z"
        },
        "colab": {
          "referenced_widgets": [
            "923a10e1f5c9406da31d9b91443f2ee2",
            "811cec37f9da481580615d38e782eb0f"
          ]
        },
        "outputId": "2d520ebb-22d4-4f8d-ca09-91b265585eca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "923a10e1f5c9406da31d9b91443f2ee2"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "`torch_dtype` is deprecated! Use `dtype` instead!\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/1.50G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "811cec37f9da481580615d38e782eb0f"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-0.6B and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "PeftModelForSequenceClassification(\n  (base_model): LoraModel(\n    (model): Qwen3ForSequenceClassification(\n      (model): Qwen3Model(\n        (embed_tokens): Embedding(151936, 1024, padding_idx=151643)\n        (layers): ModuleList(\n          (0-27): 28 x Qwen3DecoderLayer(\n            (self_attn): Qwen3Attention(\n              (q_proj): lora.Linear(\n                (base_layer): Linear(in_features=1024, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=1024, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n              (v_proj): lora.Linear(\n                (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=1024, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n            )\n            (mlp): Qwen3MLP(\n              (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n              (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n              (act_fn): SiLUActivation()\n            )\n            (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n            (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n          )\n        )\n        (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n        (rotary_emb): Qwen3RotaryEmbedding()\n      )\n      (score): ModulesToSaveWrapper(\n        (original_module): Linear(in_features=1024, out_features=5000, bias=False)\n        (modules_to_save): ModuleDict(\n          (default): Linear(in_features=1024, out_features=5000, bias=False)\n        )\n      )\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess"
      ],
      "metadata": {
        "id": "10387705"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 256\n",
        "\n",
        "def preprocess(dataset_split, select_columns: List[str]):\n",
        "    def run_tokenizer(row):\n",
        "      return tokenizer(\n",
        "          row[\"text\"],\n",
        "          padding=\"max_length\",\n",
        "          truncation=True,\n",
        "          max_length=max_length,\n",
        "      )\n",
        "\n",
        "    def add_text(row):\n",
        "      row[\"text\"] = row[\"title\"] + \" \" + row[\"description\"]\n",
        "\n",
        "      return row\n",
        "\n",
        "    dataset_split = dataset_split.map(add_text)\n",
        "\n",
        "    encoded_dataset = dataset_split.map(run_tokenizer, batched=True)\n",
        "\n",
        "    encoded_dataset = encoded_dataset.remove_columns(\n",
        "        [col for col in encoded_dataset.column_names if col not in select_columns]\n",
        "    )\n",
        "\n",
        "    return encoded_dataset.with_format(\"torch\")\n",
        "\n",
        "train_dataset = preprocess(dataset['train'], [\"input_ids\", \"attention_mask\", \"label\"])\n",
        "valid_dataset = preprocess(dataset['valid'], [\"input_ids\", \"attention_mask\", \"label\"])\n",
        "test_dataset = preprocess(dataset['test'], [\"label\", \"text\"])"
      ],
      "metadata": {
        "id": "fe2221af",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T05:25:41.530144Z",
          "iopub.execute_input": "2026-02-17T05:25:41.530420Z",
          "iopub.status.idle": "2026-02-17T05:25:44.868178Z",
          "shell.execute_reply.started": "2026-02-17T05:25:41.530394Z",
          "shell.execute_reply": "2026-02-17T05:25:44.867489Z"
        },
        "colab": {
          "referenced_widgets": [
            "042c1a42a52d42f5b76c4c31f16f5f05",
            "951b6c33f988484da5b158212e58db02",
            "cec70b5fb1d14a63a060d30cc857d6df",
            "a116c824c55a4a2ebb9dc63ac0d3f6cb",
            "fc0127cecd624f7eaada65e58cd7dd1e",
            "257766ddedc5411b880ad74301e082ac"
          ]
        },
        "outputId": "7e079d48-6f5d-4d21-938b-40fc639d4a92"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "042c1a42a52d42f5b76c4c31f16f5f05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "951b6c33f988484da5b158212e58db02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cec70b5fb1d14a63a060d30cc857d6df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a116c824c55a4a2ebb9dc63ac0d3f6cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc0127cecd624f7eaada65e58cd7dd1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "257766ddedc5411b880ad74301e082ac"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics"
      ],
      "metadata": {
        "id": "61ae7f96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=-1)\n",
        "    results = accuracy.compute(predictions=preds, references=labels)\n",
        "    results.update(\n",
        "        f1.compute(predictions=preds, references=labels, average=\"macro\")\n",
        "    )\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "6925906a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T05:25:44.869104Z",
          "iopub.execute_input": "2026-02-17T05:25:44.869357Z",
          "iopub.status.idle": "2026-02-17T05:25:46.386697Z",
          "shell.execute_reply.started": "2026-02-17T05:25:44.869332Z",
          "shell.execute_reply": "2026-02-17T05:25:46.386144Z"
        },
        "colab": {
          "referenced_widgets": [
            "23b11e7cf644467a834687e56b3dc1e2",
            "9b2fda48a6d14c18a789d367ddcb079b"
          ]
        },
        "outputId": "af4448b7-ece4-4397-a302-2b9202bb82dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23b11e7cf644467a834687e56b3dc1e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b2fda48a6d14c18a789d367ddcb079b"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "d8b54633"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Arguments"
      ],
      "metadata": {
        "id": "99a6b1ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\"./qwen3_agnews_grid\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    warmup_steps=0,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    gradient_accumulation_steps=4,\n",
        "    fp16=False, # Changed from torch.cuda.is_available() to False to resolve bfloat16 AMP issue\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer_kwargs = dict(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "527fc936",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T05:25:46.387537Z",
          "iopub.execute_input": "2026-02-17T05:25:46.387731Z",
          "iopub.status.idle": "2026-02-17T05:25:46.435193Z",
          "shell.execute_reply.started": "2026-02-17T05:25:46.387711Z",
          "shell.execute_reply": "2026-02-17T05:25:46.434509Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search Space"
      ],
      "metadata": {
        "id": "329362be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = {}\n",
        "\n",
        "idx = 0\n",
        "for learning_rate in [1e-4, 1e-3]:\n",
        "    for num_train_epochs in [1, 2, 3]:\n",
        "        hyperparameters[idx] = {\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"num_train_epochs\": num_train_epochs\n",
        "        }\n",
        "\n",
        "        idx += 1\n"
      ],
      "metadata": {
        "id": "08fd5ee0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T05:25:46.437401Z",
          "iopub.execute_input": "2026-02-17T05:25:46.437767Z",
          "iopub.status.idle": "2026-02-17T05:25:52.850573Z",
          "shell.execute_reply.started": "2026-02-17T05:25:46.437744Z",
          "shell.execute_reply": "2026-02-17T05:25:52.849860Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "208870ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_single_experiment(\n",
        "    base_training_args: TrainingArguments,\n",
        "    trainer_cls,\n",
        "    trainer_kwargs: Dict[str, Any],\n",
        "    hp_config: Dict[str, float|int],\n",
        "    idx: int\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    base_training_args: a TrainingArguments object with default values.\n",
        "    trainer_cls: usually `Trainer`.\n",
        "    trainer_kwargs: dict with keys like model, train_dataset, eval_dataset, tokenizer, compute_metrics.\n",
        "    hp_config: specific hyperparameters for this run (e.g. lr, epochs, batch size).\n",
        "    \"\"\"\n",
        "    # 1) Clone TrainingArguments and override selected fields\n",
        "    args_dict = base_training_args.to_dict()\n",
        "    for k, v in hp_config.items():\n",
        "        args_dict[k] = v\n",
        "\n",
        "    training_args = TrainingArguments(**args_dict)\n",
        "\n",
        "    # 2) Create a fresh Trainer (important if model should be reinitialized externally)\n",
        "    trainer = trainer_cls(\n",
        "        args=training_args,\n",
        "        **trainer_kwargs,\n",
        "    )\n",
        "\n",
        "    # 3) Train and evaluate\n",
        "    train_output = trainer.train()\n",
        "    eval_metrics = trainer.evaluate()\n",
        "\n",
        "    trainer.save_model(f\"checkpoint_{idx}\")\n",
        "\n",
        "    result = {\n",
        "        \"hp_config\": hp_config,\n",
        "        \"train_samples\": train_output.metrics.get(\"train_samples\", None),\n",
        "        \"eval_metrics\": eval_metrics,\n",
        "    }\n",
        "\n",
        "    return result\n",
        "\n",
        "def grid_search_hyperparams(\n",
        "    base_training_args: TrainingArguments,\n",
        "    trainer_cls,\n",
        "    trainer_kwargs: Dict[str, Any],\n",
        "    hyperparameters: Dict[int, Dict[str, int|float]],\n",
        "    results_path: str = \"grid_search_results.jsonl\",\n",
        ") -> List[Dict[str, Any]]:\n",
        "    all_results = {}\n",
        "\n",
        "    os.makedirs(os.path.dirname(results_path) or \".\", exist_ok=True)\n",
        "\n",
        "    with open(results_path, \"w\", encoding=\"utf-8\") as f_out:\n",
        "        for idx, combo in hyperparameters.items():\n",
        "            print(\"\\n=== Running config:\", combo, \"===\")\n",
        "\n",
        "            result = run_single_experiment(\n",
        "                base_training_args=base_training_args,\n",
        "                trainer_cls=trainer_cls,\n",
        "                trainer_kwargs=deepcopy(trainer_kwargs),\n",
        "                hp_config=combo,\n",
        "                idx=idx\n",
        "            )\n",
        "\n",
        "            # Persist each result as one JSON line\n",
        "            f_out.write(json.dumps(result) + \"\\n\")\n",
        "            f_out.flush()\n",
        "\n",
        "            all_results[idx] = result\n",
        "\n",
        "    return all_results"
      ],
      "metadata": {
        "id": "062e0479",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T05:25:52.851565Z",
          "iopub.execute_input": "2026-02-17T05:25:52.851891Z",
          "iopub.status.idle": "2026-02-17T05:25:52.867056Z",
          "shell.execute_reply.started": "2026-02-17T05:25:52.851856Z",
          "shell.execute_reply": "2026-02-17T05:25:52.866364Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "bd6829fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = grid_search_hyperparams(\n",
        "    base_training_args=training_arguments,\n",
        "    trainer_cls=Trainer,\n",
        "    trainer_kwargs=trainer_kwargs,\n",
        "    hyperparameters=hyperparameters,\n",
        "    results_path=\"grid_search_results.jsonl\",\n",
        ")"
      ],
      "metadata": {
        "id": "fa47f6ab",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T05:25:52.867919Z",
          "iopub.execute_input": "2026-02-17T05:25:52.868195Z",
          "iopub.status.idle": "2026-02-17T08:21:27.791393Z",
          "shell.execute_reply.started": "2026-02-17T05:25:52.868160Z",
          "shell.execute_reply": "2026-02-17T08:21:27.790704Z"
        },
        "outputId": "15bf992b-5cf7-44cd-d190-fbbef49bee5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n=== Running config: {'learning_rate': 0.0001, 'num_train_epochs': 1} ===\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:2111: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_token` instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='79' max='79' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [79/79 13:48, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.992594</td>\n      <td>0.828000</td>\n      <td>0.825853</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 01:13]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n=== Running config: {'learning_rate': 0.0001, 'num_train_epochs': 2} ===\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:2111: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_token` instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='158' max='158' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [158/158 27:50, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.780422</td>\n      <td>0.865000</td>\n      <td>0.864585</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>12.262700</td>\n      <td>0.748375</td>\n      <td>0.870000</td>\n      <td>0.868807</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 01:13]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n=== Running config: {'learning_rate': 0.0001, 'num_train_epochs': 3} ===\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:2111: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_token` instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='237' max='237' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [237/237 41:50, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.797437</td>\n      <td>0.859000</td>\n      <td>0.858114</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>12.198700</td>\n      <td>0.710348</td>\n      <td>0.874000</td>\n      <td>0.872266</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.956700</td>\n      <td>0.709219</td>\n      <td>0.875000</td>\n      <td>0.873477</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 01:13]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n=== Running config: {'learning_rate': 0.001, 'num_train_epochs': 1} ===\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:2111: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_token` instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='79' max='79' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [79/79 13:50, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.621687</td>\n      <td>0.895000</td>\n      <td>0.894368</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 01:14]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n=== Running config: {'learning_rate': 0.001, 'num_train_epochs': 2} ===\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:2111: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_token` instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='158' max='158' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [158/158 27:52, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.692500</td>\n      <td>0.883000</td>\n      <td>0.882915</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4.189400</td>\n      <td>0.632770</td>\n      <td>0.901000</td>\n      <td>0.900274</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 01:13]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n=== Running config: {'learning_rate': 0.001, 'num_train_epochs': 3} ===\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:2111: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_token` instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='237' max='237' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [237/237 41:47, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.884094</td>\n      <td>0.850000</td>\n      <td>0.849034</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4.295300</td>\n      <td>0.671107</td>\n      <td>0.905000</td>\n      <td>0.904161</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.994100</td>\n      <td>0.789437</td>\n      <td>0.906000</td>\n      <td>0.905313</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 01:13]\n    </div>\n    "
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "best_config = max(results.items(), key=lambda r: r[1][\"eval_metrics\"].get(\"eval_f1\", 0.0))\n",
        "\n",
        "print(\"Best index:\", best_config[0])\n",
        "print(\"Best config:\", best_config[1][\"hp_config\"])\n",
        "print(\"Best metrics:\", best_config[1][\"eval_metrics\"])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T08:21:27.792354Z",
          "iopub.execute_input": "2026-02-17T08:21:27.792684Z",
          "iopub.status.idle": "2026-02-17T08:21:27.797938Z",
          "shell.execute_reply.started": "2026-02-17T08:21:27.792639Z",
          "shell.execute_reply": "2026-02-17T08:21:27.797241Z"
        },
        "id": "6fpkVLBxwETe",
        "outputId": "813f8907-7b18-490a-db2a-ecb3c622dbfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Best index: 5\nBest config: {'learning_rate': 0.001, 'num_train_epochs': 3}\nBest metrics: {'eval_loss': 0.7894369959831238, 'eval_accuracy': 0.906, 'eval_f1': 0.9053130647941987, 'eval_runtime': 75.0512, 'eval_samples_per_second': 13.324, 'eval_steps_per_second': 0.839, 'epoch': 3.0}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "466e425e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    f\"./checkpoint_{best_config[0]}\",\n",
        "    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ")\n",
        "\n",
        "results = evaluator(\"text-classification\").compute(\n",
        "    model_or_pipeline=pipeline(\"text-classification\", model=model),\n",
        "    data=test_dataset,\n",
        "    metric=evaluate.load(\"f1\"),\n",
        "    input_column=\"text\",\n",
        "    label_column=\"label\",\n",
        "    strategy=\"bootstrap\",\n",
        "    n_resamples=200\n",
        ")\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "11e427eb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-17T08:35:30.206020Z",
          "iopub.execute_input": "2026-02-17T08:35:30.206344Z",
          "iopub.status.idle": "2026-02-17T08:35:30.616555Z",
          "shell.execute_reply.started": "2026-02-17T08:35:30.206315Z",
          "shell.execute_reply": "2026-02-17T08:35:30.615582Z"
        },
        "outputId": "5fe6c036-2f4c-4fc9-9f4f-67f70658e805"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-0.6B and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_55/2008480807.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = AutoModelForSequenceClassification.from_pretrained(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34mf\"/kaggle/working/checkpoint_{best_config[0]}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpad_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    605\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   5146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_adapter_model_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5147\u001b[0m             \u001b[0madapter_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"key_mapping\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5148\u001b[0;31m             model.load_adapter(\n\u001b[0m\u001b[1;32m   5149\u001b[0m                 \u001b[0m_adapter_model_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5150\u001b[0m                 \u001b[0madapter_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madapter_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/integrations/peft.py\u001b[0m in \u001b[0;36mload_adapter\u001b[0;34m(self, peft_model_id, adapter_name, revision, token, device_map, max_memory, offload_folder, offload_index, peft_config, adapter_state_dict, low_cpu_mem_usage, is_trainable, adapter_kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# Load state dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         incompatible_keys = set_peft_model_state_dict(\n\u001b[0m\u001b[1;32m    262\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed_adapter_state_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpeft_load_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py\u001b[0m in \u001b[0;36mset_peft_model_state_dict\u001b[0;34m(model, peft_model_state_dict, adapter_name, ignore_mismatched_sizes, low_cpu_mem_usage)\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_move_adapter_to_device_of_base_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mload_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeft_model_state_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_prompt_learning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2624\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2625\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2626\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Qwen3ForSequenceClassification:\n\tsize mismatch for score.modules_to_save.default.weight: copying a param with shape torch.Size([5000, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024])."
          ],
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for Qwen3ForSequenceClassification:\n\tsize mismatch for score.modules_to_save.default.weight: copying a param with shape torch.Size([5000, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).",
          "output_type": "error"
        }
      ],
      "execution_count": null
    }
  ]
}