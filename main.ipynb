{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"colab":{"provenance":[],"gpuType":"T4","include_colab_link":true},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"d0393bc7-c07c-43d9-91e4-052738c1c254","cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/calvinli2024/CS614-genai/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"id":"d69d2840","cell_type":"markdown","source":"# Packages","metadata":{"id":"d69d2840"}},{"id":"fc729135","cell_type":"code","source":"%pip install evaluate peft","metadata":{"id":"fc729135","trusted":true},"outputs":[],"execution_count":null},{"id":"a5063f33","cell_type":"code","source":"import os\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional, Any\n\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    Trainer,\n    TrainingArguments,\n    AutoModelForCausalLM,\n    pipeline\n)\n\nimport evaluate\nfrom evaluate import evaluator\n\nimport itertools\nimport json\nfrom copy import deepcopy\n\nfrom peft import LoraConfig, TaskType, get_peft_model","metadata":{"id":"a5063f33","trusted":true},"outputs":[],"execution_count":null},{"id":"219bb5b4","cell_type":"code","source":"os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"id":"219bb5b4","trusted":true},"outputs":[],"execution_count":null},{"id":"21c40442","cell_type":"markdown","source":"# Dataset","metadata":{"id":"21c40442"}},{"id":"f17fa8ac","cell_type":"code","source":"dataset = load_dataset(\"sh0416/ag_news\")\n\ndataset = {\n    \"train\": dataset[\"train\"].shuffle(seed=42).select(range(5000)),\n    \"valid\": dataset[\"train\"].shuffle(seed=42).select(range(5000, 6000)),\n    \"test\": dataset[\"test\"].shuffle(seed=42).select(range(2000))\n}\n\nlabel_names = dataset[\"train\"][\"label\"]\nnum_labels = len(label_names)","metadata":{"id":"f17fa8ac","trusted":true},"outputs":[],"execution_count":null},{"id":"dd832b22","cell_type":"markdown","source":"# Tokenizer","metadata":{"id":"dd832b22"}},{"id":"f135bcd2","cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\")\n\n# Ensure we have a padding token (Qwen is a causal LM)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token","metadata":{"id":"f135bcd2","trusted":true},"outputs":[],"execution_count":null},{"id":"xrhA-fo_kx63","cell_type":"markdown","source":"# Model","metadata":{"id":"xrhA-fo_kx63"}},{"id":"085db5df","cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"Qwen/Qwen3-0.6B\",\n    num_labels=num_labels,\n    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n    pad_token_id=tokenizer.pad_token_id,\n)\n\nlora_config = LoraConfig(\n    task_type=TaskType.SEQ_CLS,\n    inference_mode=False, # set to False for training\n    r=8, # dimension of the smaller matrices\n    lora_alpha=32, # scaling factor\n    lora_dropout=0.1 # dropout of LoRA layers\n)\n\nmodel = get_peft_model(model, lora_config)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel.to(device)","metadata":{"id":"085db5df","trusted":true},"outputs":[],"execution_count":null},{"id":"10387705","cell_type":"markdown","source":"# Preprocess","metadata":{"id":"10387705"}},{"id":"fe2221af","cell_type":"code","source":"max_length = 256\n\ndef preprocess(dataset_split, select_columns: List[str]):\n    def run_tokenizer(row):\n      return tokenizer(\n          row[\"text\"],\n          padding=\"max_length\",\n          truncation=True,\n          max_length=max_length,\n      )\n\n    def add_text(row):\n      row[\"text\"] = row[\"title\"] + \" \" + row[\"description\"]\n\n      return row\n\n    dataset_split = dataset_split.map(add_text)\n\n    encoded_dataset = dataset_split.map(run_tokenizer, batched=True)\n\n    encoded_dataset = encoded_dataset.remove_columns(\n        [col for col in encoded_dataset.column_names if col not in select_columns]\n    )\n\n    return encoded_dataset.with_format(\"torch\")\n\ntrain_dataset = preprocess(dataset['train'], [\"input_ids\", \"attention_mask\", \"label\"])\nvalid_dataset = preprocess(dataset['valid'], [\"input_ids\", \"attention_mask\", \"label\"])\ntest_dataset = preprocess(dataset['test'], [\"label\", \"text\"])","metadata":{"id":"fe2221af","trusted":true},"outputs":[],"execution_count":null},{"id":"61ae7f96","cell_type":"markdown","source":"# Metrics","metadata":{"id":"61ae7f96"}},{"id":"6925906a","cell_type":"code","source":"accuracy = evaluate.load(\"accuracy\")\nf1 = evaluate.load(\"f1\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = logits.argmax(axis=-1)\n    results = accuracy.compute(predictions=preds, references=labels)\n    results.update(\n        f1.compute(predictions=preds, references=labels, average=\"macro\")\n    )\n\n    return results","metadata":{"id":"6925906a","trusted":true},"outputs":[],"execution_count":null},{"id":"d8b54633","cell_type":"markdown","source":"# Hyperparameter Tuning","metadata":{"id":"d8b54633"}},{"id":"99a6b1ec","cell_type":"markdown","source":"## Training Arguments","metadata":{"id":"99a6b1ec"}},{"id":"527fc936","cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=\"./qwen3_agnews_grid\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_strategy=\"steps\",\n    logging_steps=100,\n    num_train_epochs=1,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    learning_rate=5e-5,\n    weight_decay=0.01,\n    warmup_steps=0, # Setting to 0 to replace warmup_ratio, as it is deprecated.\n    lr_scheduler_type=\"cosine\",\n    gradient_accumulation_steps=4,\n    fp16=False, # Changed from torch.cuda.is_available() to False to resolve bfloat16 AMP issue\n    report_to=\"none\",\n)\n\ntrainer_kwargs = dict(\n    model=model,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n    compute_metrics=compute_metrics,\n)","metadata":{"id":"527fc936","trusted":true},"outputs":[],"execution_count":null},{"id":"329362be","cell_type":"markdown","source":"## Search Space","metadata":{"id":"329362be"}},{"id":"08fd5ee0","cell_type":"code","source":"idx = 0\nfor learning_rate in [1e-4, 1e-3]:\n    for num_train_epochs in [1, 2, 3]:\n        hyperparameters[idx] = {\n            \"learning_rate\": learning_rate,\n            \"num_train_epochs\": epochs\n        }\n\n        idx += 1\n","metadata":{"id":"08fd5ee0","trusted":true},"outputs":[],"execution_count":null},{"id":"208870ac","cell_type":"markdown","source":"## Helper Functions","metadata":{"id":"208870ac"}},{"id":"062e0479","cell_type":"code","source":"def run_single_experiment(\n    base_training_args: TrainingArguments,\n    trainer_cls,\n    trainer_kwargs: Dict[str, Any],\n    hp_config: Dict[str, float|int],\n) -> Dict[str, Any]:\n    \"\"\"\n    base_training_args: a TrainingArguments object with default values.\n    trainer_cls: usually `Trainer`.\n    trainer_kwargs: dict with keys like model, train_dataset, eval_dataset, tokenizer, compute_metrics.\n    hp_config: specific hyperparameters for this run (e.g. lr, epochs, batch size).\n    \"\"\"\n    # 1) Clone TrainingArguments and override selected fields\n    args_dict = base_training_args.to_dict()\n    for k, v in hp_config.items():\n        args_dict[k] = v\n\n    training_args = TrainingArguments(**args_dict)\n\n    # 2) Create a fresh Trainer (important if model should be reinitialized externally)\n    trainer = trainer_cls(\n        args=training_args,\n        **trainer_kwargs,\n    )\n\n    # 3) Train and evaluate\n    train_output = trainer.train()\n    eval_metrics = trainer.evaluate()\n\n    result = {\n        \"hp_config\": hp_config,\n        \"train_samples\": train_output.metrics.get(\"train_samples\", None),\n        \"eval_metrics\": eval_metrics,\n    }\n\n    return result\n\ndef grid_search_hyperparams(\n    base_training_args: TrainingArguments,\n    trainer_cls,\n    trainer_kwargs: Dict[str, Any],\n    hyperparameters: Dict[int, Dict[str, int|float]],\n    results_path: str = \"grid_search_results.jsonl\",\n) -> List[Dict[str, Any]]:\n    all_results = {}\n\n    os.makedirs(os.path.dirname(results_path) or \".\", exist_ok=True)\n\n    with open(results_path, \"w\", encoding=\"utf-8\") as f_out:\n        for idx, combo in hyperparameters.items():\n            print(\"\\n=== Running config:\", combo, \"===\")\n\n            result = run_single_experiment(\n                base_training_args=base_training_args,\n                trainer_cls=trainer_cls,\n                trainer_kwargs=deepcopy(trainer_kwargs),\n                hp_config=combo,\n            )\n\n            trainer_cls.save_model(f\"checkpoint_{idx}\")\n            \n            # Persist each result as one JSON line\n            f_out.write(json.dumps(result) + \"\\n\")\n            f_out.flush()\n\n            all_results[idx] = result\n\n    return all_results","metadata":{"id":"062e0479","trusted":true},"outputs":[],"execution_count":null},{"id":"bd6829fa","cell_type":"markdown","source":"# Train","metadata":{"id":"bd6829fa"}},{"id":"fa47f6ab","cell_type":"code","source":"results = grid_search_hyperparams(\n    base_training_args=training_arguments,\n    trainer_cls=Trainer,\n    trainer_kwargs=trainer_kwargs,\n    hyperparameters=hyperparameters,\n    results_path=\"grid_search_results.jsonl\",\n)\n\n# 5) Pick best config by metric (e.g. accuracy)\nbest = max(results.items(), key=lambda r: r[1][\"eval_metrics\"].get(\"eval_accuracy\", 0.0))\n\nprint(\"Best index:\", best[0])\nprint(\"Best config:\", best[1][\"hp_config\"])\nprint(\"Best metrics:\", best[1[\"eval_metrics\"])","metadata":{"id":"fa47f6ab","trusted":true},"outputs":[],"execution_count":null},{"id":"466e425e","cell_type":"markdown","source":"# Inference","metadata":{"id":"466e425e"}},{"id":"11e427eb","cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    f\"./qwen3_agnews_grid/checkpoing-{best[0]}\",\n    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n    pad_token_id=tokenizer.pad_token_id,\n)\n\nresults = evaluator(\"text-classification\").compute(\n    model_or_pipeline=pipeline(\"text-classification\", model=model),\n    data=test_dataset,\n    metric=evaluate.load(\"f1\"),\n    input_column=\"text\",\n    label_column=\"label\",\n    strategy=\"bootstrap\", \n    n_resamples=200\n)\n\nprint(results)","metadata":{"id":"11e427eb","trusted":true},"outputs":[],"execution_count":null}]}