{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69d2840",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5063f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Any\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import itertools\n",
    "import json\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8a8a5f",
   "metadata": {},
   "source": [
    "# Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219bb5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen3-4B\"  # 4B, open-weight, causal LM for research use.[web:10]\n",
    "DATASET_NAME = \"sh0416/ag_news\"  # AG News topic classification dataset.[web:8]\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c40442",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17fa8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(DATASET_NAME)  # splits: train, test.[web:8]\n",
    "\n",
    "label_names = dataset[\"train\"].features[\"label\"].names\n",
    "num_labels = len(label_names)\n",
    "\n",
    "# For a small, quick run, you can optionally subsample.\n",
    "# dataset[\"train\"] = dataset[\"train\"].shuffle(seed=42).select(range(2000))\n",
    "# dataset[\"test\"] = dataset[\"test\"].shuffle(seed=42).select(range(500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd832b22",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Ensure we have a padding token (Qwen is a causal LM)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d9175",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085db5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels,\n",
    "    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10387705",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2221af",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256\n",
    "\n",
    "def preprocess(examples):\n",
    "    # AG News has \"text\" and \"label\".[web:8]\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess, batched=True)\n",
    "encoded_dataset = encoded_dataset.remove_columns(\n",
    "    [col for col in encoded_dataset[\"train\"].column_names if col not in [\"input_ids\", \"attention_mask\", \"label\"]]\n",
    ")\n",
    "encoded_dataset = encoded_dataset.with_format(\"torch\")\n",
    "\n",
    "train_dataset = encoded_dataset[\"train\"]\n",
    "eval_dataset = encoded_dataset[\"test\"]  # or create your own split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ae7f96",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6925906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    results = accuracy.compute(predictions=preds, references=labels)\n",
    "    results.update(\n",
    "        f1.compute(predictions=preds, references=labels, average=\"macro\")\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b54633",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6b1ec",
   "metadata": {},
   "source": [
    "## Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527fc936",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"./qwen3_agnews_grid\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    gradient_accumulation_steps=4,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer_kwargs = dict(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329362be",
   "metadata": {},
   "source": [
    "## Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fd5ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"learning_rate\": [5e-5, 1e-4],\n",
    "    \"num_train_epochs\": [1, 2, 3],\n",
    "    \"per_device_train_batch_size\": [4, 8],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208870ac",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062e0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_experiment(\n",
    "    base_training_args: TrainingArguments,\n",
    "    trainer_cls,\n",
    "    trainer_kwargs: Dict[str, Any],\n",
    "    hp_config: Dict[str, Any],\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    base_training_args: a TrainingArguments object with default values.\n",
    "    trainer_cls: usually `Trainer`.\n",
    "    trainer_kwargs: dict with keys like model, train_dataset, eval_dataset, tokenizer, compute_metrics.\n",
    "    hp_config: specific hyperparameters for this run (e.g. lr, epochs, batch size).\n",
    "    \"\"\"\n",
    "    # 1) Clone TrainingArguments and override selected fields\n",
    "    args_dict = base_training_args.to_dict()\n",
    "    for k, v in hp_config.items():\n",
    "        args_dict[k] = v\n",
    "\n",
    "    training_args = TrainingArguments(**args_dict)\n",
    "\n",
    "    # 2) Create a fresh Trainer (important if model should be reinitialized externally)\n",
    "    trainer = trainer_cls(\n",
    "        args=training_args,\n",
    "        **trainer_kwargs,\n",
    "    )\n",
    "\n",
    "    # 3) Train and evaluate\n",
    "    train_output = trainer.train()\n",
    "    eval_metrics = trainer.evaluate()\n",
    "\n",
    "    result = {\n",
    "        \"hp_config\": hp_config,\n",
    "        \"train_runtime\": train_output.training_time,\n",
    "        \"train_samples\": train_output.metrics.get(\"train_samples\", None),\n",
    "        \"eval_metrics\": eval_metrics,\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "def grid_search_hyperparams(\n",
    "    base_training_args: TrainingArguments,\n",
    "    trainer_cls,\n",
    "    trainer_kwargs: Dict[str, Any],\n",
    "    search_space: Dict[str, List[Any]],\n",
    "    results_path: str = \"grid_search_results.jsonl\",\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    search_space: dict of hyperparameter -> list of values, e.g.\n",
    "        {\n",
    "            \"learning_rate\": [5e-5, 1e-4],\n",
    "            \"num_train_epochs\": [1, 2, 3],\n",
    "            \"per_device_train_batch_size\": [4, 8],\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Cartesian product of search space.[web:14][web:17]\n",
    "    keys = list(search_space.keys())\n",
    "    value_lists = [search_space[k] for k in keys]\n",
    "\n",
    "    all_results: List[Dict[str, Any]] = []\n",
    "\n",
    "    os.makedirs(os.path.dirname(results_path) or \".\", exist_ok=True)\n",
    "\n",
    "    with open(results_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        for combo in itertools.product(*value_lists):\n",
    "            hp_config = {k: v for k, v in zip(keys, combo)}\n",
    "            print(\"\\n=== Running config:\", hp_config, \"===\")\n",
    "\n",
    "            result = run_single_experiment(\n",
    "                base_training_args=base_training_args,\n",
    "                trainer_cls=trainer_cls,\n",
    "                trainer_kwargs=deepcopy(trainer_kwargs),\n",
    "                hp_config=hp_config,\n",
    "            )\n",
    "\n",
    "            # Persist each result as one JSON line\n",
    "            f_out.write(json.dumps(result) + \"\\n\")\n",
    "            f_out.flush()\n",
    "\n",
    "            all_results.append(result)\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6829fa",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa47f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grid_search_hyperparams(\n",
    "    base_training_args=training_arguments,\n",
    "    trainer_cls=Trainer,\n",
    "    trainer_kwargs=trainer_kwargs,\n",
    "    search_space=search_space,\n",
    "    results_path=\"grid_search_results.jsonl\",\n",
    ")\n",
    "\n",
    "# 5) Pick best config by metric (e.g. accuracy)\n",
    "best = max(results, key=lambda r: r[\"eval_metrics\"].get(\"eval_accuracy\", 0.0))\n",
    "print(\"Best config:\", best[\"hp_config\"])\n",
    "print(\"Best metrics:\", best[\"eval_metrics\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e425e",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ed7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: name for i, name in enumerate(label_names)}\n",
    "\n",
    "def infer(texts: List[str]):\n",
    "    encodings = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings)\n",
    "        logits = outputs.logits\n",
    "        preds = logits.argmax(dim=-1).cpu().tolist()\n",
    "        \n",
    "    return [id2label[p] for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b109520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_texts = [\n",
    "    \"Stocks rose today as the market reacted positively to the latest earnings reports.\",\n",
    "    \"The team secured a last-minute victory in the championship game.\",\n",
    "]\n",
    "\n",
    "print(infer(example_texts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs614-genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
